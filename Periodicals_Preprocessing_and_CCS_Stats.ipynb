{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of the ACM Periodicals Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from xml.dom import minidom\n",
    "from xml.parsers.expat import ExpatError\n",
    "from tqdm import tqdm\n",
    "\n",
    "len(\"CCS->Mathematics of computing->Mathematical software\".split(\"->\"))-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "content -> (article_rec) -> (categories | ccs2012 | keywords | abstract) \n",
    "ccs2012\n",
    "keywords\n",
    "abstract\n",
    "concept_significance <br>\n",
    "\n",
    "kewywords -> kw <br>\n",
    "abstract -> par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(\"periodicals/*/*.xml\")\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kw_preproc(kw):\n",
    "    return kw.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_dict  = {\"doi\":[], \"abstract\":[], \"ft_body\":[], \"ccs\":[], \"keywords\":[]}\n",
    "count_ccs      = {}\n",
    "count_ccs_root = {}\n",
    "count_ccs_kw   = {}\n",
    "bad_data_count = 0\n",
    "bad_xml_count  = 0\n",
    "count_abstract = 0\n",
    "count_body     = 0\n",
    "\n",
    "for i, path in enumerate(tqdm(all_files)):\n",
    "    \n",
    "\n",
    "    try:                                             \n",
    "        mydoc = minidom.parse(path)\n",
    "    except ExpatError:\n",
    "        bad_xml_count += 1\n",
    "        continue\n",
    "\n",
    "\n",
    "    article_rec    = mydoc.getElementsByTagName('article_rec')\n",
    "\n",
    "    for articles in article_rec:\n",
    "        doi_number = articles.getElementsByTagName('doi_number')\n",
    "        article_id = articles.getElementsByTagName('article_id')\n",
    "\n",
    "        if(len(doi_number) > 1):\n",
    "            bad_data_count += 1\n",
    "            # print(\"Two doi numbers\")\n",
    "\n",
    "        # print(doi_number[0].firstChild.data)\n",
    "        if(doi_number[0].firstChild != None):\n",
    "            articles_dict[\"doi\"].append(doi_number[0].firstChild.data)\n",
    "        elif(article_id[0].firstChild != None):\n",
    "            articles_dict[\"doi\"].append(article_id[0].firstChild.data)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        abstract = articles.getElementsByTagName('abstract')\n",
    "\n",
    "        if(len(abstract) > 1):\n",
    "            bad_data_count += 1\n",
    "            articles_dict[\"abstract\"].append(abstract[0].getElementsByTagName('par')[0].firstChild.data)\n",
    "            count_abstract += 1\n",
    "            # print(\"Two abstracts\")\n",
    "        elif(len(abstract) == 0):\n",
    "            bad_data_count += 1\n",
    "            # print(\"No Abstract\")\n",
    "            articles_dict[\"abstract\"].append(np.nan)\n",
    "        else:\n",
    "            if(abstract[0].getElementsByTagName('par')[0].firstChild != None):\n",
    "                articles_dict[\"abstract\"].append(abstract[0].getElementsByTagName('par')[0].firstChild.data)\n",
    "            else:\n",
    "                articles_dict[\"abstract\"].append(abstract[0].firstChild.data)\n",
    "            count_abstract += 1\n",
    "\n",
    "        ft_body = articles.getElementsByTagName('ft_body')\n",
    "\n",
    "        if(len(ft_body) > 1):\n",
    "            bad_data_count += 1\n",
    "            articles_dict[\"ft_body\"].append(ft_body[0].firstChild.data)\n",
    "            # print(\"Two bodies\")\n",
    "            count_body     += 1\n",
    "        elif(len(ft_body) == 0):\n",
    "            bad_data_count += 1\n",
    "            # print(\"No Body\")\n",
    "            articles_dict[\"ft_body\"].append(np.nan)\n",
    "        else:\n",
    "            articles_dict[\"ft_body\"].append(ft_body[0].firstChild.data)\n",
    "            count_body     += 1\n",
    "\n",
    "        kw_list = []\n",
    "        for kw in articles.getElementsByTagName('kw'):\n",
    "            # print(kw.firstChild.data) \n",
    "            kw_list.append(kw_preproc(kw.firstChild.data))\n",
    "            \n",
    "        if len(kw_list) > 0:\n",
    "            articles_dict['keywords'].append(kw_list)\n",
    "        else:\n",
    "            articles_dict['keywords'].append(np.nan)\n",
    "\n",
    "        ccs_dict = {}\n",
    "\n",
    "        for concept in articles.getElementsByTagName('concept'):\n",
    "            concept_desc         = concept.getElementsByTagName('concept_desc')\n",
    "            concept_significance = concept.getElementsByTagName('concept_significance')\n",
    "\n",
    "            significance = int(concept_significance[0].firstChild.data)\n",
    "            concept_tree = concept_desc[0].firstChild.data\n",
    "            \n",
    "            if('->' in concept_tree):\n",
    "                concept_root = concept_tree.split(\"->\")[1]\n",
    "            elif('~' in concept_tree):\n",
    "                concept_root = concept_tree.split(\"~\")[0]\n",
    "            else:\n",
    "                # print(concept_tree)\n",
    "                concept_root = concept_tree\n",
    "            # print(concept_tree)\n",
    "            # print(concept_root)\n",
    "            # print(significance)\n",
    "\n",
    "            ## We count concepts only once !\n",
    "            if concept_tree not in ccs_dict.keys():\n",
    "\n",
    "                if concept_root in count_ccs_root.keys():\n",
    "                    count_ccs_root[concept_root] += 1\n",
    "                else:\n",
    "                    count_ccs_root[concept_root]  = 1\n",
    "            \n",
    "                if concept_tree in count_ccs.keys():\n",
    "                    count_ccs[concept_tree] += 1\n",
    "                else:\n",
    "                    count_ccs[concept_tree]  = 1\n",
    "\n",
    "                if concept_tree not in count_ccs_kw.keys() and len(kw_list) > 0:\n",
    "                    count_ccs_kw[concept_tree] = {}\n",
    "                \n",
    "                for kw in kw_list:\n",
    "                    if kw in count_ccs_kw[concept_tree].keys():\n",
    "                        count_ccs_kw[concept_tree][kw] += 1\n",
    "                    else:\n",
    "                        count_ccs_kw[concept_tree][kw]  = 1\n",
    "\n",
    "                ## Adds concept to ccs_dict with sign level\n",
    "                ccs_dict[concept_tree] = significance\n",
    "\n",
    "            elif concept_tree in ccs_dict.keys():\n",
    "                ## Adds concept to ccs_dict with MAX sign level\n",
    "                ccs_dict[concept_tree] = max(significance, ccs_dict[concept_tree])        \n",
    "\n",
    "        \n",
    "        articles_dict['ccs'].append(ccs_dict)\n",
    "\n",
    "\n",
    "\n",
    "print(bad_data_count, bad_xml_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of abstracts: \", count_abstract)\n",
    "print(\"Number of bodies: \", count_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the created data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/count_ccs.json', 'w') as fp:\n",
    "    json.dump(count_ccs, fp)\n",
    "\n",
    "with open('Data/count_ccs_root.json', 'w') as fp:\n",
    "    json.dump(count_ccs_root, fp)\n",
    "\n",
    "with open('Data/count_ccs_kw.json', 'w') as fp:\n",
    "    json.dump(count_ccs_kw, fp)\n",
    "\n",
    "with open('Data/articles_dict.json', 'w') as fp:\n",
    "    json.dump(articles_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats on the ACM DataBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "with open('Data/count_ccs.json', 'r') as fp:\n",
    "    count_ccs = json.load(fp)\n",
    " \n",
    "    # Print the type of data variable\n",
    "    print(\"Type:\", type(count_ccs))\n",
    "\n",
    "with open('Data/count_ccs_root.json', 'r') as fp:\n",
    "    count_ccs_root = json.load(fp)\n",
    "\n",
    "with open('Data/count_ccs_kw.json', 'r') as fp:\n",
    "    count_ccs_kw = json.load(fp)\n",
    "\n",
    "with open('Data/articles_dict.json', 'r') as fp:\n",
    "    articles_dict = json.load(fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Descr of the Created DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>ft_body</th>\n",
       "      <th>ccs</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107908</th>\n",
       "      <td>10.1145/2767134</td>\n",
       "      <td>&lt;p&gt;Online social media allow users to interact...</td>\n",
       "      <td>\\n Detection of Political Manipulation in Onli...</td>\n",
       "      <td>{'CCS-&gt;Information systems-&gt;World Wide Web-&gt;We...</td>\n",
       "      <td>[online social media, machine learning, opinio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107909</th>\n",
       "      <td>10.1145/2767135</td>\n",
       "      <td>&lt;p&gt;A classifier that determines if a webpage i...</td>\n",
       "      <td>\\n Improving Researcher Homepage Classi.cation...</td>\n",
       "      <td>{'CCS-&gt;Information systems-&gt;Information retrie...</td>\n",
       "      <td>[researcher homepage classification, co-traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107910</th>\n",
       "      <td>10.1145/2789211</td>\n",
       "      <td>&lt;p&gt;There has been a recent swell of interest i...</td>\n",
       "      <td>\\n Diversionary Comments under Blog Posts JING...</td>\n",
       "      <td>{'Mathematics of computing~Bayesian networks':...</td>\n",
       "      <td>[diversionary comments, classification, corefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107911</th>\n",
       "      <td>10.1145/2790304</td>\n",
       "      <td>&lt;p&gt;This work addresses the problem of estimati...</td>\n",
       "      <td>\\n Estimating Clustering Coef.cients and Size ...</td>\n",
       "      <td>{'CCS-&gt;Theory of computation-&gt;Design and analy...</td>\n",
       "      <td>[estimation, clustering coefficient, sampling,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107912</th>\n",
       "      <td>10.1145/2812812</td>\n",
       "      <td>&lt;p&gt;The Web 2.0 brought new requirements to the...</td>\n",
       "      <td>\\n Fona: Quantitative Metric to Measure Focus ...</td>\n",
       "      <td>{'CCS-&gt;Hardware': 500}</td>\n",
       "      <td>[aria, focus navigation, web accessibility]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    doi                                           abstract  \\\n",
       "107908  10.1145/2767134  <p>Online social media allow users to interact...   \n",
       "107909  10.1145/2767135  <p>A classifier that determines if a webpage i...   \n",
       "107910  10.1145/2789211  <p>There has been a recent swell of interest i...   \n",
       "107911  10.1145/2790304  <p>This work addresses the problem of estimati...   \n",
       "107912  10.1145/2812812  <p>The Web 2.0 brought new requirements to the...   \n",
       "\n",
       "                                                  ft_body  \\\n",
       "107908  \\n Detection of Political Manipulation in Onli...   \n",
       "107909  \\n Improving Researcher Homepage Classi.cation...   \n",
       "107910  \\n Diversionary Comments under Blog Posts JING...   \n",
       "107911  \\n Estimating Clustering Coef.cients and Size ...   \n",
       "107912  \\n Fona: Quantitative Metric to Measure Focus ...   \n",
       "\n",
       "                                                      ccs  \\\n",
       "107908  {'CCS->Information systems->World Wide Web->We...   \n",
       "107909  {'CCS->Information systems->Information retrie...   \n",
       "107910  {'Mathematics of computing~Bayesian networks':...   \n",
       "107911  {'CCS->Theory of computation->Design and analy...   \n",
       "107912                             {'CCS->Hardware': 500}   \n",
       "\n",
       "                                                 keywords  \n",
       "107908  [online social media, machine learning, opinio...  \n",
       "107909  [researcher homepage classification, co-traini...  \n",
       "107910  [diversionary comments, classification, corefe...  \n",
       "107911  [estimation, clustering coefficient, sampling,...  \n",
       "107912        [aria, focus navigation, web accessibility]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df = pd.DataFrame(articles_dict)\n",
    "articles_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df.keywords.isna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['ccs'].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Most popular concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15\n",
    "ccs_ids = np.argsort(list(count_ccs.values()))[::-1]\n",
    "popular_ccs = np.array(list(count_ccs.keys()))[ccs_ids][:N]\n",
    "print(\"Here is a list of the most popular concepts: \")\n",
    "print(popular_ccs)\n",
    "print(\"And here are their occurences:\", np.sort(list(count_ccs.values()))[::-1][:N])\n",
    "print(\"There is {0} concepts with keywords out of {1} concepts.\".format(len(count_ccs_kw), len(count_ccs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stats on Width of Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_df = pd.DataFrame({\"ccs_root\": articles_df['doi'], \"occurences\": [len(dic.values()) for dic in articles_df['ccs']]})\n",
    "depth_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_df[depth_df['occurences'] > 0].hist(bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stats on Depth of Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_of_concepts = [len(ccs.split(\"->\"))-1 if '->' in ccs else len(ccs.split(\"~\"))-1 if '~' in ccs else 1 for ccs in count_ccs.keys()]\n",
    "\n",
    "print(np.median(depth_of_concepts), np.mean(depth_of_concepts), np.max(depth_of_concepts), np.min(depth_of_concepts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min théorique est de 1, max théorique est de 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of different CCS roots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_root_df = pd.DataFrame({\"ccs_root\": count_ccs_root.keys(), \"occurences\": count_ccs_root.values()})\n",
    "ccs_root_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_root_df[ccs_root_df['occurences'] > 5].sort_values(by=['occurences'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keywords Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On a single ccs concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_name = 'CCS->Human-centered computing->Human computer interaction (HCI)'\n",
    "\n",
    "def create_kw_occ_df(ccs_name):\n",
    "    kw_occ_df = pd.DataFrame({\"keywords\": count_ccs_kw[ccs_name].keys(), \"occurences\": count_ccs_kw[ccs_name].values()})\n",
    "    return kw_occ_df\n",
    "\n",
    "kw_occ_df = create_kw_occ_df(ccs_name)\n",
    "kw_occ_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_occ_df.hist(bins=30, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_occ_df[kw_occ_df['occurences'] > 5].sort_values(by=['occurences'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stats on overall keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_count_avg = 0\n",
    "kw_count_max = 0\n",
    "kw_entry_num = 1\n",
    "kw_agg_dict  = {}\n",
    "\n",
    "for val in count_ccs_kw.values():\n",
    "    for kw, count in val.items():\n",
    "        kw_count_avg += (count-kw_count_avg)/kw_entry_num\n",
    "        if(kw_count_max < count):\n",
    "            kw_count_max = count\n",
    "        kw_entry_num+=1\n",
    "\n",
    "        if kw in kw_agg_dict.keys():\n",
    "            kw_agg_dict[kw] += 1\n",
    "        else:\n",
    "            kw_agg_dict[kw]  = 1\n",
    "\n",
    "print(kw_count_max, kw_count_avg, kw_entry_num, len(kw_agg_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_agg_df = pd.DataFrame({\"keyword_names\": kw_agg_dict.keys(), \"occurences\": kw_agg_dict.values()})\n",
    "kw_agg_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kw_agg_df[kw_agg_df['occurences'] >= 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of Keywords in a Doc for Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vector(sentence, vocab_words):\n",
    "    return [1 if token in sentence else 0 for token in vocab_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filters the dataframe only to include articles with keywords\n",
    "filtered_articles_df = articles_df.dropna(subset='keywords')\n",
    "# [articles_df['keywords'].notnull()]\n",
    "\n",
    "## Sets the number of keywords used for vectorization\n",
    "nb_key_words = int(1e4)\n",
    "kw_vocab = kw_agg_df.sort_values(\"occurences\")['keyword_names'][::-1][:nb_key_words].tolist()\n",
    "\n",
    "## Computes the vector representation for each document\n",
    "filtered_articles_df[\"BOWrepresentation_kw\"]    = filtered_articles_df[\"keywords\"].apply(lambda sentence: sentence_vector(sentence, kw_vocab))\n",
    "filtered_articles_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Article Dendrogram for Binary BOW\")\n",
    "\n",
    "# Selecting Binary BOW as Information\n",
    "selected_data = filtered_articles_df.iloc[:, 5].array\n",
    "selected_data = np.array([np.array(el) for el in selected_data])# Algorithm expects 2D array as an observation vector\n",
    "clusters = shc.linkage(selected_data, \n",
    "            method='ward', \n",
    "            metric=\"euclidean\")# Euclidean distance \n",
    "shc.dendrogram(Z=clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric  can be ‘braycurtis’, ‘canberra’, ‘chebyshev’, ‘cityblock’, ‘correlation’, ‘cosine’, ‘dice’, ‘euclidean’, ‘hamming’, ‘jaccard’, ‘jensenshannon’, ‘kulczynski1’, ‘mahalanobis’, ‘matching’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’, ‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’, ‘sqeuclidean’, ‘yule’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf-Idf BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "filtered_articles_df[\"keywords_str\"]    = filtered_articles_df[\"keywords\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "\n",
    "pipe_kw = Pipeline([('count', CountVectorizer(vocabulary=kw_vocab)),\n",
    "                       ('tfidf', TfidfTransformer())]).fit(filtered_articles_df[\"keywords_str\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the TF-IDF representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of arrays is a good solution to assign arrays as value in dataframe\n",
    "tf_idf_list = list(pipe_kw.transform(filtered_articles_df[\"keywords_str\"]).toarray())\n",
    "np.array(tf_idf_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_articles_df[\"tf-idf_kw\"] = tf_idf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_articles_df[[\"doi\", \"BOWrepresentation_kw\", \"tf-idf_kw\"]].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Article Dendrogram for TF-ISF BOW\")\n",
    "\n",
    "# Selecting Binary BOW as Information\n",
    "selected_data = filtered_articles_df.iloc[:, 6].array\n",
    "selected_data = np.array([np.array(el) for el in selected_data])# Algorithm expects 2D array as an observation vector\n",
    "clusters = shc.linkage(selected_data, \n",
    "            method='ward', \n",
    "            metric=\"euclidean\")# Euclidean distance \n",
    "shc.dendrogram(Z=clusters)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "00dac3d85057902516a7de3d1bb919e2487cdfcc669671ff52e056662c37d510"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
